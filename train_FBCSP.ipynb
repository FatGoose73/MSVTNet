{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import dpeeg and set global seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dpeeg\n",
    "\n",
    "dpeeg.set_seed()\n",
    "print(dpeeg.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBCSPSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CSP:\n",
    "    def __init__(self,m_filters):\n",
    "        self.m_filters = m_filters\n",
    "\n",
    "    def fit(self,x_train,y_train):\n",
    "        x_data = np.copy(x_train)\n",
    "        y_labels = np.copy(y_train)\n",
    "        n_trials, n_channels, n_samples = x_data.shape\n",
    "        cov_x = np.zeros((2, n_channels, n_channels), dtype=np.float32)\n",
    "        for i in range(n_trials):\n",
    "            x_trial = x_data[i, :, :]\n",
    "            y_trial = y_labels[i]\n",
    "            cov_x_trial = np.matmul(x_trial, np.transpose(x_trial))\n",
    "            cov_x_trial /= np.trace(cov_x_trial)\n",
    "            cov_x[y_trial, :, :] += cov_x_trial\n",
    "\n",
    "        cov_x = np.asarray([cov_x[cls]/np.sum(y_labels==cls) for cls in range(2)])\n",
    "        cov_combined = cov_x[0]+cov_x[1]\n",
    "        eig_values, u_mat = scipy.linalg.eig(cov_combined,cov_x[0])\n",
    "        sort_indices = np.argsort(abs(eig_values))[::-1]\n",
    "        eig_values = eig_values[sort_indices]\n",
    "        u_mat = u_mat[:,sort_indices]\n",
    "        u_mat = np.transpose(u_mat)\n",
    "\n",
    "        return eig_values, u_mat\n",
    "\n",
    "    def transform(self,x_trial,eig_vectors):\n",
    "        z_trial = np.matmul(eig_vectors, x_trial)\n",
    "        z_trial_selected = z_trial[:self.m_filters,:]\n",
    "        z_trial_selected = np.append(z_trial_selected,z_trial[-self.m_filters:,:],axis=0)\n",
    "        sum_z2 = np.sum(z_trial_selected**2, axis=1)\n",
    "        sum_z = np.sum(z_trial_selected, axis=1)\n",
    "        var_z = (sum_z2 - (sum_z ** 2)/z_trial_selected.shape[1]) / (z_trial_selected.shape[1] - 1)\n",
    "        sum_var_z = sum(var_z)\n",
    "        return np.log(var_z/sum_var_z)\n",
    "\n",
    "\n",
    "class FBCSP:\n",
    "    def __init__(self,m_filters):\n",
    "        self.m_filters = m_filters\n",
    "        self.fbcsp_filters_multi=[]\n",
    "\n",
    "    def fit(self,x_train_fb,y_train):\n",
    "        y_classes_unique = np.unique(y_train)\n",
    "        n_classes = len(y_classes_unique)\n",
    "        self.csp = CSP(self.m_filters)\n",
    "\n",
    "        def get_csp(x_train_fb, y_train_cls):\n",
    "            fbcsp_filters = {}\n",
    "            for j in range(x_train_fb.shape[0]):\n",
    "                x_train = x_train_fb[j, :, :, :]\n",
    "                eig_values, u_mat = self.csp.fit(x_train, y_train_cls)\n",
    "                fbcsp_filters.update({j: {'eig_val': eig_values, 'u_mat': u_mat}})\n",
    "            return fbcsp_filters\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            cls_of_interest = y_classes_unique[i]\n",
    "            select_class_labels = lambda cls, y_labels: [0 if y == cls else 1 for y in y_labels]\n",
    "            y_train_cls = np.asarray(select_class_labels(cls_of_interest, y_train))\n",
    "            fbcsp_filters=get_csp(x_train_fb,y_train_cls)\n",
    "            self.fbcsp_filters_multi.append(fbcsp_filters)\n",
    "\n",
    "    def transform(self,x_data,class_idx=0):\n",
    "        n_fbanks, n_trials, n_channels, n_samples = x_data.shape\n",
    "        x_features = np.zeros((n_trials,self.m_filters*2*len(x_data)))\n",
    "        for i in range(n_fbanks):\n",
    "            eig_vectors = self.fbcsp_filters_multi[class_idx].get(i).get('u_mat')\n",
    "            eig_values = self.fbcsp_filters_multi[class_idx].get(i).get('eig_val')\n",
    "            for k in range(n_trials):\n",
    "                x_trial = np.copy(x_data[i,k,:,:])\n",
    "                csp_feat = self.csp.transform(x_trial,eig_vectors)\n",
    "                for j in range(self.m_filters):\n",
    "                    x_features[k, i * self.m_filters * 2 + (j+1) * 2 - 2]  = csp_feat[j]\n",
    "                    x_features[k, i * self.m_filters * 2 + (j+1) * 2 - 1]= csp_feat[-j-1]\n",
    "\n",
    "        return x_features\n",
    "\n",
    "\n",
    "class FeatureSelect:\n",
    "    def __init__(self, n_features_select=4, n_csp_pairs=2):\n",
    "        self.n_features_select = n_features_select\n",
    "        self.n_csp_pairs = n_csp_pairs\n",
    "        self.features_selected_indices=[]\n",
    "\n",
    "    def fit(self,x_train_features,y_train):\n",
    "        MI_features = self.MIBIF(x_train_features, y_train)\n",
    "        MI_sorted_idx = np.argsort(MI_features)[::-1]\n",
    "        features_selected = MI_sorted_idx[:self.n_features_select]\n",
    "\n",
    "        paired_features_idx = self.select_CSP_pairs(features_selected, self.n_csp_pairs)\n",
    "        x_train_features_selected = x_train_features[:, paired_features_idx]\n",
    "        self.features_selected_indices = paired_features_idx\n",
    "\n",
    "        return x_train_features_selected\n",
    "\n",
    "    def transform(self,x_test_features):\n",
    "        return x_test_features[:,self.features_selected_indices]\n",
    "\n",
    "    def MIBIF(self, x_features, y_labels):\n",
    "        def get_prob_pw(x,d,i,h):\n",
    "            n_data = d.shape[0]\n",
    "            t=d[:,i]\n",
    "            kernel = lambda u: np.exp(-0.5*(u**2))/np.sqrt(2*np.pi)\n",
    "            prob_x = 1 / (n_data * h) * sum(kernel((np.ones((len(t)))*x- t)/h))\n",
    "            return prob_x\n",
    "\n",
    "        def get_pd_pw(d, i, x_trials):\n",
    "            n_data, n_dimensions = d.shape\n",
    "            if n_dimensions==1:\n",
    "                i=1\n",
    "            t = d[:,i]\n",
    "            min_x = np.min(t)\n",
    "            max_x = np.max(t)\n",
    "            n_trials = x_trials.shape[0]\n",
    "            std_t = np.std(t)\n",
    "            if std_t==0:\n",
    "                h=0.005\n",
    "            else:\n",
    "                h=(4./(3*n_data))**(0.2)*std_t\n",
    "            prob_x = np.zeros((n_trials))\n",
    "            for j in range(n_trials):\n",
    "                prob_x[j] = get_prob_pw(x_trials[j],d,i,h)\n",
    "            return prob_x, x_trials, h\n",
    "\n",
    "        y_classes = np.unique(y_labels)\n",
    "        n_classes = len(y_classes)\n",
    "        n_trials = len(y_labels)\n",
    "        prob_w = []\n",
    "        x_cls = {}\n",
    "        for i in range(n_classes):\n",
    "            cls = y_classes[i]\n",
    "            cls_indx = np.where(y_labels == cls)[0]\n",
    "            prob_w.append(len(cls_indx) / n_trials)\n",
    "            x_cls.update({i: x_features[cls_indx, :]})\n",
    "\n",
    "        prob_x_w = np.zeros((n_classes, n_trials, x_features.shape[1]))\n",
    "        prob_w_x = np.zeros((n_classes, n_trials, x_features.shape[1]))\n",
    "        h_w_x = np.zeros((x_features.shape[1]))\n",
    "        mutual_info = np.zeros((x_features.shape[1]))\n",
    "        parz_win_width = 1.0 / np.log2(n_trials)\n",
    "        h_w = -np.sum(prob_w * np.log2(prob_w))\n",
    "\n",
    "        for i in range(x_features.shape[1]):\n",
    "            h_w_x[i] = 0\n",
    "            for j in range(n_classes):\n",
    "                prob_x_w[j, :, i] = get_pd_pw(x_cls.get(j), i, x_features[:, i])[0]\n",
    "\n",
    "        t_s = prob_x_w.shape\n",
    "        n_prob_w_x = np.zeros((n_classes, t_s[1], t_s[2]))\n",
    "        for i in range(n_classes):\n",
    "            n_prob_w_x[i, :, :] = prob_x_w[i] * prob_w[i]\n",
    "        prob_x = np.sum(n_prob_w_x, axis=0)\n",
    "        # prob_w_x = np.zeros((n_classes, prob_x.shape[0], prob_w.shape[1]))\n",
    "        for i in range(n_classes):\n",
    "            prob_w_x[i, :, :] = n_prob_w_x[i, :, :]/prob_x\n",
    "\n",
    "        for i in range(x_features.shape[1]):\n",
    "            for j in range(n_trials):\n",
    "                t_sum = 0.0\n",
    "                for k in range(n_classes):\n",
    "                    if prob_w_x[k, j, i] > 0:\n",
    "                        t_sum += (prob_w_x[k, j, i] * np.log2(prob_w_x[k, j, i]))\n",
    "\n",
    "                h_w_x[i] -= (t_sum / n_trials)\n",
    "\n",
    "            mutual_info[i] = h_w - h_w_x[i]\n",
    "\n",
    "        mifsg = np.asarray(mutual_info)\n",
    "        return mifsg\n",
    "\n",
    "\n",
    "    def select_CSP_pairs(self,features_selected,n_pairs):\n",
    "        features_selected+=1\n",
    "        sel_groups = np.unique(np.ceil(features_selected/n_pairs))\n",
    "        paired_features = []\n",
    "        for i in range(len(sel_groups)):\n",
    "            for j in range(n_pairs-1,-1,-1):\n",
    "                paired_features.append(sel_groups[i]*n_pairs-j)\n",
    "\n",
    "        paired_features = np.asarray(paired_features,dtype=np.int64)-1\n",
    "\n",
    "        return paired_features\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.feature_selection = False\n",
    "\n",
    "    def predict(self,x_features):\n",
    "        if self.feature_selection:\n",
    "            x_features_selected = self.feature_selection.transform(x_features)\n",
    "        else:\n",
    "            x_features_selected = x_features\n",
    "        y_predicted = self.model.predict(x_features_selected)\n",
    "        return y_predicted\n",
    "\n",
    "    def fit(self,x_features,y_train):\n",
    "        feature_selection = True\n",
    "        if feature_selection:\n",
    "            feature_selection = FeatureSelect()\n",
    "            self.feature_selection = feature_selection\n",
    "            x_train_features_selected = self.feature_selection.fit(x_features,y_train)\n",
    "        else:\n",
    "            x_train_features_selected = x_features\n",
    "        self.model.fit(x_train_features_selected,y_train)\n",
    "        y_predicted = self.model.predict(x_train_features_selected)\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject-Dependent & Session-Dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------------\n",
    "# # define subject-dependent classifier\n",
    "# # ----------------------------------- \n",
    "# import os\n",
    "# import numpy as np\n",
    "# from dpeeg.tools import Filer\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# class Trainer:\n",
    "#     def __init__(self, out_folder) -> None:\n",
    "#         self.out_folder = os.path.join(os.path.abspath(out_folder), 'FBCSPSVM')\n",
    "#         os.makedirs(self.out_folder, exist_ok=True)\n",
    "\n",
    "#     def _get_multi_class_regressed(self, y_predicted):\n",
    "#         y_predict_multi = np.asarray([np.argmin(y_predicted[i,:]) for i in range(y_predicted.shape[0])])\n",
    "#         return y_predict_multi\n",
    "\n",
    "#     def _run_sub(self, train_data, train_label, test_data, test_label):\n",
    "#         y_classes_unique = np.unique(train_label)\n",
    "#         n_classes = len(np.unique(train_label))\n",
    "\n",
    "#         fbcsp = FBCSP(4)\n",
    "#         fbcsp.fit(train_data, train_label)\n",
    "#         y_train_predicted = np.zeros((train_label.shape[0], n_classes), dtype=np.float32)\n",
    "#         y_test_predicted = np.zeros((test_label.shape[0], n_classes), dtype=np.float32)\n",
    "\n",
    "#         select_class_labels = lambda cls, y_labels: [0 if y == cls else 1 for y in y_labels]\n",
    "\n",
    "#         for j in range(n_classes):\n",
    "#             cls_of_interest = y_classes_unique[j]\n",
    "#             y_train_cls = np.asarray(select_class_labels(cls_of_interest, train_label))\n",
    "\n",
    "#             x_features_train = fbcsp.transform(train_data, class_idx=cls_of_interest)\n",
    "#             x_features_test = fbcsp.transform(test_data, class_idx=cls_of_interest)\n",
    "\n",
    "#             classifier_type = SVR(gamma='auto')\n",
    "#             classifier = Classifier(classifier_type)\n",
    "#             y_train_predicted[:, j] = classifier.fit(x_features_train, np.asarray(y_train_cls, dtype=np.float32))\n",
    "#             y_test_predicted[:, j] = classifier.predict(x_features_test)\n",
    "\n",
    "#         y_test_predicted_multi = self._get_multi_class_regressed(y_test_predicted)\n",
    "#         acc = np.sum(y_test_predicted_multi == test_label) / len(test_label)\n",
    "\n",
    "#         return y_test_predicted_multi, test_label, acc\n",
    "\n",
    "#     def run(self, dataset, dataset_name):\n",
    "#         data_folder = os.path.join(self.out_folder, dataset_name)\n",
    "#         filer = Filer(os.path.join(data_folder, 'summary.txt'))\n",
    "\n",
    "#         results = {}\n",
    "#         acc_list = []\n",
    "#         for sub in dataset.keys():\n",
    "#             print(f'Subject-{sub} Training')\n",
    "            \n",
    "#             train_data, train_label = dataset[sub]['train']\n",
    "#             test_data, test_label = dataset[sub]['test']\n",
    "#             train_data = train_data.transpose(1, 0, 2, 3)\n",
    "#             test_data = test_data.transpose(1, 0, 2, 3)\n",
    "\n",
    "#             preds, target, acc = self._run_sub(train_data, train_label, test_data, test_label)\n",
    "#             acc_list.append(acc)\n",
    "#             print(f'\\tSubject-{sub} Acc = {acc}')\n",
    "\n",
    "#             filer.write(f'sub-{sub}: {acc}\\n')\n",
    "#             results[f'sub_{sub}'] = {'preds': preds, 'target': target, 'acc': acc}\n",
    "\n",
    "#         acc = np.mean(acc_list)\n",
    "#         print(f'AvgAcc = {acc}')\n",
    "#         filer.write(f'AvgAcc = {acc}')\n",
    "#         np.save(os.path.join(data_folder, 'results'), results)\n",
    "\n",
    "#         return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bciciv2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dpeeg.data import datasets, transforms\n",
    "\n",
    "# trans = transforms.ComposeTransforms(\n",
    "#     transforms.Normalization(),\n",
    "#     transforms.FilterBank(freq=250, filter_bank=[[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]]),\n",
    "#     transforms.Augmentation('segmentation_and_reconstruction', multiply=1),\n",
    "# )\n",
    "\n",
    "# dataset = datasets.BCICIV2A(transforms=trans, mode='single_ses')\n",
    "\n",
    "# trainer = Trainer('out')\n",
    "# results = trainer.run(dataset.dataset, 'BCICIV2A_SD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bciciv2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dpeeg.data import datasets, transforms\n",
    "\n",
    "# trans = transforms.ComposeTransforms(\n",
    "#     transforms.Normalization(),\n",
    "#     transforms.FilterBank(freq=250, filter_bank=[[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]]),\n",
    "#     transforms.Augmentation('segmentation_and_reconstruction', multiply=1)\n",
    "# )\n",
    "\n",
    "# dataset = datasets.BCICIV2B(transforms=trans, mode='single_ses', test_sessions=[1])\n",
    "# trainer = Trainer('out')\n",
    "# results = trainer.run(dataset.dataset, 'BCICIV2B_SD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openbmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dpeeg.data import transforms, load\n",
    "# from scipy import signal\n",
    "\n",
    "# lowcut = 4\n",
    "# highcut = 30\n",
    "# fs = 250\n",
    "# order = 5\n",
    "# def butter_bandpass_filter(data):\n",
    "#     nyq = 0.5 * fs\n",
    "#     low = lowcut / nyq\n",
    "#     high = highcut / nyq\n",
    "#     b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "#     y = signal.filtfilt(b, a, data)\n",
    "#     return y\n",
    "\n",
    "# trans = transforms.ComposeTransforms(\n",
    "#     transforms.ApplyFunc(butter_bandpass_filter),\n",
    "#     transforms.FilterBank(freq=250, filter_bank=[[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]]),\n",
    "#     transforms.Augmentation('segmentation_and_reconstruction', multiply=1)\n",
    "# )\n",
    "\n",
    "# dataset = load('openbmi_session-dependent')\n",
    "# dataset = trans(dataset)\n",
    "# trainer = Trainer('out')\n",
    "# results = trainer.run(dataset, 'OpenBMI_SD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject-Dependent & Session-Independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bciciv2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dpeeg.data import datasets, transforms\n",
    "\n",
    "# trans = transforms.ComposeTransforms(\n",
    "#     transforms.Normalization(),\n",
    "#     transforms.FilterBank(freq=250, filter_bank=[[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]]),\n",
    "#     transforms.Augmentation('segmentation_and_reconstruction', multiply=1)\n",
    "# )\n",
    "\n",
    "# dataset = datasets.BCICIV2A(transforms=trans)\n",
    "# trainer = Trainer('out')\n",
    "# results = trainer.run(dataset, 'BCICIV2A_SI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bciciv2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dpeeg.data import transforms, datasets\n",
    "\n",
    "# trans = transforms.ComposeTransforms(\n",
    "#     transforms.Normalization(),\n",
    "#     transforms.FilterBank(freq=250, filter_bank=[[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]]),\n",
    "#     transforms.Augmentation('segmentation_and_reconstruction', multiply=1),\n",
    "# )\n",
    "\n",
    "# dataset = datasets.BCICIV2B(transforms=trans, test_sessions=[3, 4])\n",
    "# trainer = Trainer('out')\n",
    "# results = trainer.run(dataset, 'BCICIV2B_SI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openbmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dpeeg.data import transforms, load\n",
    "# from scipy import signal\n",
    "\n",
    "# lowcut = 4\n",
    "# highcut = 30\n",
    "# fs = 250\n",
    "# order = 5\n",
    "# def butter_bandpass_filter(data):\n",
    "#     nyq = 0.5 * fs\n",
    "#     low = lowcut / nyq\n",
    "#     high = highcut / nyq\n",
    "#     b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "#     y = signal.filtfilt(b, a, data)\n",
    "#     return y\n",
    "\n",
    "# trans = transforms.ComposeTransforms(\n",
    "#     transforms.ApplyFunc(butter_bandpass_filter),\n",
    "#     transforms.FilterBank(freq=250, filter_bank=[[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]]),\n",
    "#     transforms.Augmentation('segmentation_and_reconstruction', multiply=1)\n",
    "# )\n",
    "\n",
    "# dataset = load('openbmi_session-independent')\n",
    "# dataset = trans(dataset)\n",
    "# trainer = Trainer('out')\n",
    "# results = trainer.run(dataset, 'OpenBMI_SI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject-Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# define subject-independent classifier\n",
    "# -------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "from dpeeg.tools import Filer\n",
    "from dpeeg.data.functions import merge_train_test\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, out_folder) -> None:\n",
    "        self.out_folder = os.path.join(os.path.abspath(out_folder), 'FBCSPSVM')\n",
    "        os.makedirs(self.out_folder, exist_ok=True)\n",
    "\n",
    "    def _get_multi_class_regressed(self, y_predicted):\n",
    "        y_predict_multi = np.asarray([np.argmin(y_predicted[i,:]) for i in range(y_predicted.shape[0])])\n",
    "        return y_predict_multi\n",
    "\n",
    "    def _run_sub(self, train_data, train_label, test_data, test_label):\n",
    "        y_classes_unique = np.unique(train_label)\n",
    "        n_classes = len(np.unique(train_label))\n",
    "\n",
    "        fbcsp = FBCSP(4)\n",
    "        fbcsp.fit(train_data, train_label)\n",
    "        y_train_predicted = np.zeros((train_label.shape[0], n_classes), dtype=np.float32)\n",
    "        y_test_predicted = np.zeros((test_label.shape[0], n_classes), dtype=np.float32)\n",
    "\n",
    "        select_class_labels = lambda cls, y_labels: [0 if y == cls else 1 for y in y_labels]\n",
    "\n",
    "        for j in range(n_classes):\n",
    "            cls_of_interest = y_classes_unique[j]\n",
    "            y_train_cls = np.asarray(select_class_labels(cls_of_interest, train_label))\n",
    "\n",
    "            x_features_train = fbcsp.transform(train_data, class_idx=cls_of_interest)\n",
    "            x_features_test = fbcsp.transform(test_data, class_idx=cls_of_interest)\n",
    "\n",
    "            classifier_type = SVR(gamma='auto')\n",
    "            classifier = Classifier(classifier_type)\n",
    "            y_train_predicted[:, j] = classifier.fit(x_features_train, np.asarray(y_train_cls, dtype=np.float32))\n",
    "            y_test_predicted[:, j] = classifier.predict(x_features_test)\n",
    "\n",
    "        y_test_predicted_multi = self._get_multi_class_regressed(y_test_predicted)\n",
    "        acc = np.sum(y_test_predicted_multi == test_label) / len(test_label)\n",
    "\n",
    "        return y_test_predicted_multi, test_label, acc\n",
    "\n",
    "    def _trans_dataset(self, trainset, testset):\n",
    "        if self.transforms is not None:\n",
    "            sub_dataset = {-1 : {'train':list(trainset), 'test':list(testset)}}\n",
    "            sub_dataset = self.transforms(sub_dataset)\n",
    "            trainset = sub_dataset[-1]['train']\n",
    "            testset = sub_dataset[-1]['test']\n",
    "\n",
    "        return trainset, testset\n",
    "\n",
    "    def _merge_sub_dataset(self, exc_sub):\n",
    "        merge_dataset = {}\n",
    "        for sub, data in self.dataset.items():\n",
    "            if sub != exc_sub:\n",
    "                merge_dataset[sub] = merge_train_test(*data.values())\n",
    "        merge_dataset = merge_train_test(*merge_dataset.values())\n",
    "        return merge_dataset\n",
    "    \n",
    "    def _process_sub_dataset(self, sub):\n",
    "        print(f'Leave Subject {sub} Out')\n",
    "        testset = merge_train_test(*self.dataset[sub].values())\n",
    "        trainset = self._merge_sub_dataset(sub)\n",
    "        trainset, testset = self._trans_dataset(trainset, testset)\n",
    "        return trainset, testset\n",
    "\n",
    "    def run(self, dataset, dataset_name, transforms = None):\n",
    "        self.dataset = dataset\n",
    "        self.transforms = transforms\n",
    "        data_folder = os.path.join(self.out_folder, dataset_name)\n",
    "        filer = Filer(os.path.join(data_folder, 'summary.txt'))\n",
    "\n",
    "        results = {}\n",
    "        acc_list = []\n",
    "        for sub in dataset.keys():\n",
    "            if sub in range(1, 8):\n",
    "                continue\n",
    "            trainset, testset = self._process_sub_dataset(sub)\n",
    "            train_data, train_label = trainset[0], trainset[1]\n",
    "            test_data, test_label = testset[0], testset[1]\n",
    "            train_data = train_data.transpose(1, 0, 2, 3)\n",
    "            test_data = test_data.transpose(1, 0, 2, 3)\n",
    "\n",
    "            print(f'Subject-{sub} Training')\n",
    "            preds, target, acc = self._run_sub(train_data, train_label, test_data, test_label)\n",
    "            acc_list.append(acc)\n",
    "            print(f'\\tSubject-{sub} Acc = {acc}')\n",
    "\n",
    "            filer.write(f'sub-{sub}: {acc}\\n')\n",
    "            result = {'preds': preds, 'target': target, 'acc': acc}\n",
    "            np.save(os.path.join(data_folder, f'sub{sub}_res'), result)\n",
    "            results[f'sub_{sub}'] = result\n",
    "\n",
    "        acc = np.mean(acc_list)\n",
    "        print(f'AvgAcc = {acc}')\n",
    "        filer.write(f'AvgAcc = {acc}')\n",
    "        np.save(os.path.join(data_folder, 'results'), results)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bciciv2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dpeeg.data import datasets, transforms\n",
    "\n",
    "# trans = transforms.ComposeTransforms(\n",
    "#     transforms.Normalization(),\n",
    "#     transforms.FilterBank(freq=250, filter_bank=[[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]]),\n",
    "# )\n",
    "\n",
    "# dataset = datasets.BCICIV2A(transforms=trans)\n",
    "# trainer = Trainer('out')\n",
    "# results = trainer.run(dataset, 'BCICIV2A_LOSO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bciciv2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dpeeg.data import transforms, datasets\n",
    "\n",
    "# trans = transforms.ComposeTransforms(\n",
    "#     transforms.Normalization(),\n",
    "#     transforms.FilterBank(freq=250, filter_bank=[[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]]),\n",
    "# )\n",
    "\n",
    "# dataset = datasets.BCICIV2B(transforms=trans, test_sessions=[3, 4])\n",
    "# trainer = Trainer('out')\n",
    "# results = trainer.run(dataset, 'BCICIV2B_LOSO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openbmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dpeeg.data import transforms, load\n",
    "# from scipy import signal\n",
    "\n",
    "# lowcut = 4\n",
    "# highcut = 30\n",
    "# fs = 250\n",
    "# order = 5\n",
    "# def butter_bandpass_filter(data):\n",
    "#     nyq = 0.5 * fs\n",
    "#     low = lowcut / nyq\n",
    "#     high = highcut / nyq\n",
    "#     b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "#     y = signal.filtfilt(b, a, data)\n",
    "#     return y\n",
    "\n",
    "# trans = transforms.ComposeTransforms(\n",
    "#     transforms.ApplyFunc(butter_bandpass_filter),\n",
    "#     transforms.FilterBank(freq=250, filter_bank=[[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]]),\n",
    "# )\n",
    "\n",
    "# dataset = load('openbmi_session-independent')\n",
    "# trainer = Trainer('out')\n",
    "# results = trainer.run(dataset, 'OpenBMI_LOSO', trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchmetrics.functional.classification.confusion_matrix import multiclass_confusion_matrix\n",
    "\n",
    "results = np.load('./out/FBCSPSVM/OpenBMI_SI/results.npy', allow_pickle=True).item()\n",
    "\n",
    "cls_name = ['R', 'L']\n",
    "preds_all, target_all = [], []\n",
    "for sub in range(1, 55):\n",
    "    preds, target = results[f'sub_{sub}']['preds'], results[f'sub_{sub}']['target']\n",
    "    preds_all.append(preds)\n",
    "    target_all.append(target)\n",
    "preds = np.concatenate(preds_all)\n",
    "target = np.concatenate(target_all)\n",
    "\n",
    "plt.figure(figsize=(2.5, 2.5))\n",
    "cm = multiclass_confusion_matrix(torch.from_numpy(preds), torch.from_numpy(target), len(cls_name))\n",
    "ax = sns.heatmap(cm / cm.sum(1, keepdim=True), annot=True, cmap='Blues', square=True, annot_kws={'size': 'xx-large'}, cbar=False,\n",
    "                 xticklabels=cls_name, yticklabels=cls_name, fmt='.3f')\n",
    "plt.xticks(fontsize='x-large')\n",
    "plt.yticks(fontsize='x-large')\n",
    "plt.axhline(0, c='k'), plt.axhline(len(cls_name), c='k')\n",
    "plt.axvline(0, c='k'), plt.axvline(len(cls_name), c='k')\n",
    "plt.savefig('CM.png', dpi=600, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
