[Start Time]: Thu Nov 23 19:24:47 2023
[DPEEG Version]: 0.3.5
[Description]: None
[KFold:
  [trainer]: [Network architecture]:
             EEGNet(
               (filter): Sequential(
                 (0): Conv2d(1, 8, kernel_size=(1, 63), stride=(1, 1), padding=(0, 31), bias=False)
                 (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
               )
               (depthwise_conv): Sequential(
                 (0): Conv2dWithNorm(8, 16, kernel_size=(20, 1), stride=(1, 1), groups=8, bias=False, max_norm=1, p=2)
                 (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                 (2): ELU(alpha=1.0)
                 (3): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)
                 (4): Dropout(p=0.5, inplace=False)
               )
               (separable_conv): Sequential(
                 (0): Conv2d(16, 16, kernel_size=(1, 15), stride=(1, 1), padding=(0, 7), groups=16, bias=False)
                 (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
                 (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                 (3): ELU(alpha=1.0)
                 (4): AvgPool2d(kernel_size=(1, 16), stride=(1, 16), padding=0)
                 (5): Dropout(p=0.5, inplace=False)
               )
               (flatten): Flatten(start_dim=1, end_dim=-1)
               (fc): Sequential(
                 (0): Linear(in_features=112, out_features=2, bias=True)
                 (1): LogSoftmax(dim=1)
               )
             )
             =================================================================
             Layer (type:depth-idx)                   Param #
             =================================================================
             EEGNet                                   --
             ├─Sequential: 1-1                        --
             │    └─Conv2d: 2-1                       504
             │    └─BatchNorm2d: 2-2                  16
             ├─Sequential: 1-2                        --
             │    └─Conv2dWithNorm: 2-3               320
             │    └─BatchNorm2d: 2-4                  32
             │    └─ELU: 2-5                          --
             │    └─AvgPool2d: 2-6                    --
             │    └─Dropout: 2-7                      --
             ├─Sequential: 1-3                        --
             │    └─Conv2d: 2-8                       240
             │    └─Conv2d: 2-9                       256
             │    └─BatchNorm2d: 2-10                 32
             │    └─ELU: 2-11                         --
             │    └─AvgPool2d: 2-12                   --
             │    └─Dropout: 2-13                     --
             ├─Flatten: 1-4                           --
             ├─Sequential: 1-5                        --
             │    └─Linear: 2-14                      226
             │    └─LogSoftmax: 2-15                  --
             =================================================================
             Total params: 1,626
             Trainable params: 1,626
             Non-trainable params: 0
             =================================================================
             [Loss function]: NLLLoss
             [Optimizer]: Adam
             [Learning rate]: 0.001
             [Grad Acc]: 1
             [Batch Size]: 64
  [k]: 5
  [out_folder]: out
  [max_epochs_s1]: 1500
  [max_epochs_s2]: 600
  [no_increase_epochs]: 100
  [second_stage]: True
  [load_best_state]: True
  [var_check]: val_inacc
  [isolate_testset]: True
  [shuffle]: True
  [seed]: 42
  [verbose]: INFO
]
[Custom dataset]
---------- Sub_1 ----------
Acc = 80.80% | Kappa = 0.62

---------- Sub_2 ----------
Acc = 100.00% | Kappa = 1.00

---------- Sub_3 ----------
Acc = 97.20% | Kappa = 0.94

---------- Sub_4 ----------
Acc = 65.20% | Kappa = 0.30

---------- Sub_5 ----------
Acc = 98.00% | Kappa = 0.96

---------- Sub_6 ----------
Acc = 79.60% | Kappa = 0.59

---------- Sub_7 ----------
Acc = 49.60% | Kappa = -0.01

---------- Sub_8 ----------
Acc = 69.20% | Kappa = 0.38

---------- Sub_9 ----------
Acc = 85.20% | Kappa = 0.70

---------- Sub_10 ----------
Acc = 71.20% | Kappa = 0.42

---------- Sub_11 ----------
Acc = 46.00% | Kappa = -0.08

---------- Sub_12 ----------
Acc = 73.20% | Kappa = 0.46

---------- Sub_13 ----------
Acc = 52.40% | Kappa = 0.05

---------- Sub_14 ----------
Acc = 57.60% | Kappa = 0.15

---------- Sub_15 ----------
Acc = 72.40% | Kappa = 0.45

---------- Sub_16 ----------
Acc = 58.80% | Kappa = 0.18

---------- Sub_17 ----------
Acc = 79.60% | Kappa = 0.59

---------- Sub_18 ----------
Acc = 94.00% | Kappa = 0.88

---------- Sub_19 ----------
Acc = 83.60% | Kappa = 0.67

---------- Sub_20 ----------
Acc = 56.40% | Kappa = 0.13

---------- Sub_21 ----------
Acc = 98.40% | Kappa = 0.97

---------- Sub_22 ----------
Acc = 90.40% | Kappa = 0.81

---------- Sub_23 ----------
Acc = 69.20% | Kappa = 0.38

---------- Sub_24 ----------
Acc = 47.20% | Kappa = -0.06

---------- Sub_25 ----------
Acc = 55.60% | Kappa = 0.11

---------- Sub_26 ----------
Acc = 49.20% | Kappa = -0.02

---------- Sub_27 ----------
Acc = 50.40% | Kappa = 0.01

---------- Sub_28 ----------
Acc = 92.80% | Kappa = 0.86

---------- Sub_29 ----------
Acc = 86.80% | Kappa = 0.74

---------- Sub_30 ----------
Acc = 69.20% | Kappa = 0.38

---------- Sub_31 ----------
Acc = 76.40% | Kappa = 0.53

---------- Sub_32 ----------
Acc = 79.20% | Kappa = 0.58

---------- Sub_33 ----------
Acc = 99.60% | Kappa = 0.99

---------- Sub_34 ----------
Acc = 59.20% | Kappa = 0.18

---------- Sub_35 ----------
Acc = 86.80% | Kappa = 0.74

---------- Sub_36 ----------
Acc = 96.00% | Kappa = 0.92

---------- Sub_37 ----------
Acc = 95.60% | Kappa = 0.91

---------- Sub_38 ----------
Acc = 49.20% | Kappa = -0.02

---------- Sub_39 ----------
Acc = 88.00% | Kappa = 0.76

---------- Sub_40 ----------
Acc = 60.40% | Kappa = 0.21

---------- Sub_41 ----------
Acc = 55.20% | Kappa = 0.10

---------- Sub_42 ----------
Acc = 50.00% | Kappa = 0.00

---------- Sub_43 ----------
Acc = 77.20% | Kappa = 0.54

---------- Sub_44 ----------
Acc = 97.20% | Kappa = 0.94

---------- Sub_45 ----------
Acc = 88.80% | Kappa = 0.78

---------- Sub_46 ----------
Acc = 48.80% | Kappa = -0.02

---------- Sub_47 ----------
Acc = 46.00% | Kappa = -0.08

---------- Sub_48 ----------
Acc = 64.00% | Kappa = 0.28

---------- Sub_49 ----------
Acc = 73.20% | Kappa = 0.46

---------- Sub_50 ----------
Acc = 57.20% | Kappa = 0.14

---------- Sub_51 ----------
Acc = 64.00% | Kappa = 0.28

---------- Sub_52 ----------
Acc = 72.80% | Kappa = 0.46

---------- Sub_53 ----------
Acc = 55.20% | Kappa = 0.10

---------- Sub_54 ----------
Acc = 50.40% | Kappa = 0.01

---------- MODEL ----------
Acc = 71.66% | Kappa = 0.43
