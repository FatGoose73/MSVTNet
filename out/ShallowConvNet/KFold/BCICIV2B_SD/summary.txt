[Start Time]: Thu Nov 23 16:46:00 2023
[DPEEG Version]: 0.3.5
[Description]: None
[KFold:
  [trainer]: [Network architecture]:
             ShallowConvNet(
               (conv): Sequential(
                 (0): Conv2dWithNorm(1, 40, kernel_size=(1, 14), stride=(1, 1), bias=False, max_norm=2, p=2)
                 (1): Conv2dWithNorm(40, 40, kernel_size=(3, 1), stride=(1, 1), groups=40, bias=False, max_norm=2, p=2)
                 (2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                 (3): Lambda()
                 (4): AvgPool2d(kernel_size=(1, 35), stride=(1, 7), padding=0)
                 (5): Lambda()
               )
               (head): Sequential(
                 (0): Flatten(start_dim=1, end_dim=-1)
                 (1): Dropout(p=0.5, inplace=False)
                 (2): LinearWithNorm(in_features=5480, out_features=2, bias=True, max_norm=0.5, p=2)
                 (3): LogSoftmax(dim=1)
               )
             )
             ==========================================================================================
             Layer (type:depth-idx)                   Output Shape              Param #
             ==========================================================================================
             ShallowConvNet                           [1, 2]                    --
             ├─Sequential: 1-1                        [1, 40, 1, 137]           --
             │    └─Conv2dWithNorm: 2-1               [1, 40, 3, 987]           560
             │    └─Conv2dWithNorm: 2-2               [1, 40, 1, 987]           120
             │    └─BatchNorm2d: 2-3                  [1, 40, 1, 987]           80
             │    └─Lambda: 2-4                       [1, 40, 1, 987]           --
             │    └─AvgPool2d: 2-5                    [1, 40, 1, 137]           --
             │    └─Lambda: 2-6                       [1, 40, 1, 137]           --
             ├─Sequential: 1-2                        [1, 2]                    --
             │    └─Flatten: 2-7                      [1, 5480]                 --
             │    └─Dropout: 2-8                      [1, 5480]                 --
             │    └─LinearWithNorm: 2-9               [1, 2]                    10,962
             │    └─LogSoftmax: 2-10                  [1, 2]                    --
             ==========================================================================================
             Total params: 11,722
             Trainable params: 11,722
             Non-trainable params: 0
             Total mult-adds (M): 1.79
             ==========================================================================================
             Input size (MB): 0.01
             Forward/backward pass size (MB): 1.58
             Params size (MB): 0.05
             Estimated Total Size (MB): 1.64
             ==========================================================================================
             [Loss function]: NLLLoss
             [Optimizer]: Adam
             [Learning rate]: 0.001
             [Grad Acc]: 1
             [Batch Size]: 64
  [k]: 5
  [out_folder]: out
  [max_epochs_s1]: 1500
  [max_epochs_s2]: 600
  [no_increase_epochs]: 100
  [second_stage]: True
  [load_best_state]: True
  [var_check]: val_inacc
  [isolate_testset]: True
  [shuffle]: True
  [seed]: 42
  [verbose]: INFO
]
[BCICIV2B:
  [subjects]: None
  [tmin]: 0
  [tmax]: 4
  [preprocess]: None
  [transforms]: ComposeTransforms(
                 (0): Normalization(mode=z-score, factor_new=0.001, verbose=None)
                 (1): Augmentation(method=segmentation_and_reconstruction, only_train=True, kwargs={'multiply': 1})
                 (2): Unsqueeze(dim=1)
                )
  [test_size]: 0.25
  [mode]: single_ses
  [test_sessions]: [1]
  [picks]: None
  [baseline]: None
  [seed]: 42
  [verbose]: None
]
---------- Sub_1 ----------
Acc = 56.00% | Kappa = 0.12

---------- Sub_2 ----------
Acc = 57.33% | Kappa = 0.15

---------- Sub_3 ----------
Acc = 43.33% | Kappa = -0.13

---------- Sub_4 ----------
Acc = 86.29% | Kappa = 0.73

---------- Sub_5 ----------
Acc = 83.43% | Kappa = 0.67

---------- Sub_6 ----------
Acc = 78.67% | Kappa = 0.57

---------- Sub_7 ----------
Acc = 65.33% | Kappa = 0.31

---------- Sub_8 ----------
Acc = 74.00% | Kappa = 0.48

---------- Sub_9 ----------
Acc = 44.00% | Kappa = -0.12

---------- MODEL ----------
Acc = 65.38% | Kappa = 0.31
