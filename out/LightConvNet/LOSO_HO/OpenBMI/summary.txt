[Start Time]: Sun Jan  7 03:18:39 2024
[DPEEG Version]: 0.3.5
[Description]: None
[LOSO_HO:
  [trainer]: [Network architecture]:
             LightConvNet(
               (spacial_block): Sequential(
                 (0): Conv2d(9, 64, kernel_size=(20, 1), stride=(1, 1))
                 (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                 (2): ELU(alpha=1.0)
               )
               (temporal_block): LogVarLayer()
               (conv): LightweightConv1d()
               (classify): Sequential(
                 (0): Linear(in_features=64, out_features=2, bias=True)
                 (1): LogSoftmax(dim=1)
               )
             )
             =================================================================
             Layer (type:depth-idx)                   Param #
             =================================================================
             LightConvNet                             --
             ├─Sequential: 1-1                        --
             │    └─Conv2d: 2-1                       11,584
             │    └─BatchNorm2d: 2-2                  128
             │    └─ELU: 2-3                          --
             ├─LogVarLayer: 1-2                       --
             ├─LightweightConv1d: 1-3                 32
             ├─Sequential: 1-4                        --
             │    └─Linear: 2-4                       130
             │    └─LogSoftmax: 2-5                   --
             =================================================================
             Total params: 11,874
             Trainable params: 11,874
             Non-trainable params: 0
             =================================================================
             [Loss function]: NLLLoss
             [Optimizer]: Adam
             [Learning rate]: 0.002
             [Grad Acc]: 1
             [Batch Size]: 512
  [out_folder]: out
  [max_epochs_s1]: 500
  [no_increase_epochs]: 40
  [var_check]: None
  [split_val]: True
  [test_size]: 0.25
  [second_stage]: True
  [load_best_state]: True
  [max_epochs_s2]: 200
  [seed]: 42
  [verbose]: INFO
]
[Custom dataset]
---------- Sub_1 ----------
Acc = 79.75% | Kappa = 0.60

---------- Sub_2 ----------
Acc = 80.25% | Kappa = 0.61

---------- Sub_3 ----------
Acc = 94.50% | Kappa = 0.89

---------- Sub_4 ----------
Acc = 71.25% | Kappa = 0.43

---------- Sub_5 ----------
Acc = 92.25% | Kappa = 0.85

---------- Sub_6 ----------
Acc = 84.00% | Kappa = 0.68

---------- Sub_7 ----------
Acc = 65.75% | Kappa = 0.31

---------- Sub_8 ----------
Acc = 69.00% | Kappa = 0.38

---------- Sub_9 ----------
Acc = 83.50% | Kappa = 0.67

---------- Sub_10 ----------
Acc = 62.25% | Kappa = 0.25

---------- Sub_11 ----------
Acc = 59.25% | Kappa = 0.19

---------- Sub_12 ----------
Acc = 72.25% | Kappa = 0.44

---------- Sub_13 ----------
Acc = 54.00% | Kappa = 0.08

---------- Sub_14 ----------
Acc = 75.25% | Kappa = 0.50

---------- Sub_15 ----------
Acc = 56.75% | Kappa = 0.13

---------- Sub_16 ----------
Acc = 70.25% | Kappa = 0.40

---------- Sub_17 ----------
Acc = 74.25% | Kappa = 0.49

---------- Sub_18 ----------
Acc = 83.50% | Kappa = 0.67

---------- Sub_19 ----------
Acc = 77.50% | Kappa = 0.55

---------- Sub_20 ----------
Acc = 76.75% | Kappa = 0.53

---------- Sub_21 ----------
Acc = 86.50% | Kappa = 0.73

---------- Sub_22 ----------
Acc = 84.00% | Kappa = 0.68

---------- Sub_23 ----------
Acc = 69.75% | Kappa = 0.39

---------- Sub_24 ----------
Acc = 54.75% | Kappa = 0.10

---------- Sub_25 ----------
Acc = 63.75% | Kappa = 0.27

---------- Sub_26 ----------
Acc = 64.00% | Kappa = 0.28

---------- Sub_27 ----------
Acc = 62.00% | Kappa = 0.24

---------- Sub_28 ----------
Acc = 97.25% | Kappa = 0.94

---------- Sub_29 ----------
Acc = 57.75% | Kappa = 0.15

---------- Sub_30 ----------
Acc = 70.75% | Kappa = 0.42

---------- Sub_31 ----------
Acc = 76.25% | Kappa = 0.52

---------- Sub_32 ----------
Acc = 86.00% | Kappa = 0.72

---------- Sub_33 ----------
Acc = 97.75% | Kappa = 0.95

---------- Sub_34 ----------
Acc = 53.50% | Kappa = 0.07

---------- Sub_35 ----------
Acc = 65.00% | Kappa = 0.30

---------- Sub_36 ----------
Acc = 90.00% | Kappa = 0.80

---------- Sub_37 ----------
Acc = 96.50% | Kappa = 0.93

---------- Sub_38 ----------
Acc = 64.25% | Kappa = 0.29

---------- Sub_39 ----------
Acc = 86.00% | Kappa = 0.72

---------- Sub_40 ----------
Acc = 64.75% | Kappa = 0.30

---------- Sub_41 ----------
Acc = 66.50% | Kappa = 0.33

---------- Sub_42 ----------
Acc = 69.75% | Kappa = 0.39

---------- Sub_43 ----------
Acc = 85.50% | Kappa = 0.71

---------- Sub_44 ----------
Acc = 92.75% | Kappa = 0.86

---------- Sub_45 ----------
Acc = 91.00% | Kappa = 0.82

---------- Sub_46 ----------
Acc = 70.00% | Kappa = 0.40

---------- Sub_47 ----------
Acc = 72.00% | Kappa = 0.44

---------- Sub_48 ----------
Acc = 59.50% | Kappa = 0.19

---------- Sub_49 ----------
Acc = 69.75% | Kappa = 0.39

---------- Sub_50 ----------
Acc = 52.25% | Kappa = 0.05

---------- Sub_51 ----------
Acc = 68.00% | Kappa = 0.36

---------- Sub_52 ----------
Acc = 76.00% | Kappa = 0.52

---------- Sub_53 ----------
Acc = 60.25% | Kappa = 0.20

---------- Sub_54 ----------
Acc = 64.00% | Kappa = 0.28

---------- MODEL ----------
Acc = 73.52% | Kappa = 0.47
