[Start Time]: Thu Jan 11 11:24:40 2024
[DPEEG Version]: 0.3.5
[Description]: None
[LOSO_HO:
  [trainer]: [Network architecture]:
             MSVTNet(
               (mstsconv): ModuleList(
                 (0): Sequential(
                   (0): TSConv(
                     (0): Conv2d(1, 9, kernel_size=(1, 15), stride=(1, 1), padding=same, bias=False)
                     (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (2): Conv2d(9, 18, kernel_size=(20, 1), stride=(1, 1), groups=9, bias=False)
                     (3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (4): ELU(alpha=1.0)
                     (5): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)
                     (6): Dropout(p=0.1, inplace=False)
                     (7): Conv2d(18, 18, kernel_size=(1, 15), stride=(1, 1), padding=same, groups=18, bias=False)
                     (8): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (9): ELU(alpha=1.0)
                     (10): AvgPool2d(kernel_size=(1, 7), stride=(1, 7), padding=0)
                     (11): Dropout(p=0.1, inplace=False)
                   )
                   (1): Rearrange('b d 1 t -> b t d')
                 )
                 (1): Sequential(
                   (0): TSConv(
                     (0): Conv2d(1, 9, kernel_size=(1, 31), stride=(1, 1), padding=same, bias=False)
                     (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (2): Conv2d(9, 18, kernel_size=(20, 1), stride=(1, 1), groups=9, bias=False)
                     (3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (4): ELU(alpha=1.0)
                     (5): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)
                     (6): Dropout(p=0.1, inplace=False)
                     (7): Conv2d(18, 18, kernel_size=(1, 15), stride=(1, 1), padding=same, groups=18, bias=False)
                     (8): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (9): ELU(alpha=1.0)
                     (10): AvgPool2d(kernel_size=(1, 7), stride=(1, 7), padding=0)
                     (11): Dropout(p=0.1, inplace=False)
                   )
                   (1): Rearrange('b d 1 t -> b t d')
                 )
                 (2): Sequential(
                   (0): TSConv(
                     (0): Conv2d(1, 9, kernel_size=(1, 63), stride=(1, 1), padding=same, bias=False)
                     (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (2): Conv2d(9, 18, kernel_size=(20, 1), stride=(1, 1), groups=9, bias=False)
                     (3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (4): ELU(alpha=1.0)
                     (5): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)
                     (6): Dropout(p=0.1, inplace=False)
                     (7): Conv2d(18, 18, kernel_size=(1, 15), stride=(1, 1), padding=same, groups=18, bias=False)
                     (8): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (9): ELU(alpha=1.0)
                     (10): AvgPool2d(kernel_size=(1, 7), stride=(1, 7), padding=0)
                     (11): Dropout(p=0.1, inplace=False)
                   )
                   (1): Rearrange('b d 1 t -> b t d')
                 )
                 (3): Sequential(
                   (0): TSConv(
                     (0): Conv2d(1, 9, kernel_size=(1, 125), stride=(1, 1), padding=same, bias=False)
                     (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (2): Conv2d(9, 18, kernel_size=(20, 1), stride=(1, 1), groups=9, bias=False)
                     (3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (4): ELU(alpha=1.0)
                     (5): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)
                     (6): Dropout(p=0.1, inplace=False)
                     (7): Conv2d(18, 18, kernel_size=(1, 15), stride=(1, 1), padding=same, groups=18, bias=False)
                     (8): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (9): ELU(alpha=1.0)
                     (10): AvgPool2d(kernel_size=(1, 7), stride=(1, 7), padding=0)
                     (11): Dropout(p=0.1, inplace=False)
                   )
                   (1): Rearrange('b d 1 t -> b t d')
                 )
               )
               (branch_head): ModuleList(
                 (0-3): 4 x ClsHead(
                   (0): Flatten(start_dim=1, end_dim=-1)
                   (1): Linear(in_features=306, out_features=2, bias=True)
                   (2): LogSoftmax(dim=1)
                 )
               )
               (transformer): Transformer(
                 (pos_embedding): PositionalEncoding()
                 (dropout): Dropout(p=0.3, inplace=False)
                 (trans): TransformerEncoder(
                   (layers): ModuleList(
                     (0): TransformerEncoderLayer(
                       (self_attn): MultiheadAttention(
                         (out_proj): NonDynamicallyQuantizableLinear(in_features=72, out_features=72, bias=True)
                       )
                       (linear1): Linear(in_features=72, out_features=72, bias=True)
                       (dropout): Dropout(p=0.3, inplace=False)
                       (linear2): Linear(in_features=72, out_features=72, bias=True)
                       (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
                       (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
                       (dropout1): Dropout(p=0.3, inplace=False)
                       (dropout2): Dropout(p=0.3, inplace=False)
                     )
                   )
                   (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
                 )
               )
               (last_head): ClsHead(
                 (0): Flatten(start_dim=1, end_dim=-1)
                 (1): Linear(in_features=72, out_features=2, bias=True)
                 (2): LogSoftmax(dim=1)
               )
             )
             ===============================================================================================
             Layer (type:depth-idx)                                                 Param #
             ===============================================================================================
             MSVTNet                                                                --
             ├─ModuleList: 1-1                                                      --
             │    └─Sequential: 2-1                                                 --
             │    │    └─TSConv: 3-1                                                855
             │    │    └─Rearrange: 3-2                                             --
             │    └─Sequential: 2-2                                                 --
             │    │    └─TSConv: 3-3                                                999
             │    │    └─Rearrange: 3-4                                             --
             │    └─Sequential: 2-3                                                 --
             │    │    └─TSConv: 3-5                                                1,287
             │    │    └─Rearrange: 3-6                                             --
             │    └─Sequential: 2-4                                                 --
             │    │    └─TSConv: 3-7                                                1,845
             │    │    └─Rearrange: 3-8                                             --
             ├─ModuleList: 1-2                                                      --
             │    └─ClsHead: 2-5                                                    --
             │    │    └─Flatten: 3-9                                               --
             │    │    └─Linear: 3-10                                               614
             │    │    └─LogSoftmax: 3-11                                           --
             │    └─ClsHead: 2-6                                                    --
             │    │    └─Flatten: 3-12                                              --
             │    │    └─Linear: 3-13                                               614
             │    │    └─LogSoftmax: 3-14                                           --
             │    └─ClsHead: 2-7                                                    --
             │    │    └─Flatten: 3-15                                              --
             │    │    └─Linear: 3-16                                               614
             │    │    └─LogSoftmax: 3-17                                           --
             │    └─ClsHead: 2-8                                                    --
             │    │    └─Flatten: 3-18                                              --
             │    │    └─Linear: 3-19                                               614
             │    │    └─LogSoftmax: 3-20                                           --
             ├─Transformer: 1-3                                                     72
             │    └─PositionalEncoding: 2-9                                         1,296
             │    └─Dropout: 2-10                                                   --
             │    └─TransformerEncoder: 2-11                                        --
             │    │    └─ModuleList: 3-21                                           31,824
             │    │    └─LayerNorm: 3-22                                            144
             ├─ClsHead: 1-4                                                         --
             │    └─Flatten: 2-12                                                   --
             │    └─Linear: 2-13                                                    146
             │    └─LogSoftmax: 2-14                                                --
             ===============================================================================================
             Total params: 40,924
             Trainable params: 40,924
             Non-trainable params: 0
             ===============================================================================================
             [Loss function]: JointCrossEntoryLoss()
             [Optimizer]: Adam
             [Learning rate]: 0.002
             [Grad Acc]: 1
             [Batch Size]: 512
  [out_folder]: out
  [max_epochs_s1]: 500
  [no_increase_epochs]: 40
  [var_check]: None
  [split_val]: True
  [test_size]: 0.25
  [second_stage]: True
  [load_best_state]: True
  [max_epochs_s2]: 200
  [seed]: 42
  [verbose]: INFO
]
[Custom dataset]
---------- Sub_1 ----------
Acc = 85.25% | Kappa = 0.71

---------- Sub_2 ----------
Acc = 86.50% | Kappa = 0.73

---------- Sub_3 ----------
Acc = 97.75% | Kappa = 0.95

---------- Sub_4 ----------
Acc = 74.75% | Kappa = 0.50

---------- Sub_5 ----------
Acc = 92.50% | Kappa = 0.85

---------- Sub_6 ----------
Acc = 88.75% | Kappa = 0.77

---------- Sub_7 ----------
Acc = 73.50% | Kappa = 0.47

---------- Sub_8 ----------
Acc = 76.50% | Kappa = 0.53

---------- Sub_9 ----------
Acc = 82.50% | Kappa = 0.65

---------- Sub_10 ----------
Acc = 60.50% | Kappa = 0.21

---------- Sub_11 ----------
Acc = 65.75% | Kappa = 0.31

---------- Sub_12 ----------
Acc = 78.00% | Kappa = 0.56

---------- Sub_13 ----------
Acc = 65.25% | Kappa = 0.31

---------- Sub_14 ----------
Acc = 80.25% | Kappa = 0.61

---------- Sub_15 ----------
Acc = 62.50% | Kappa = 0.25

---------- Sub_16 ----------
Acc = 68.00% | Kappa = 0.36

---------- Sub_17 ----------
Acc = 83.25% | Kappa = 0.66

---------- Sub_18 ----------
Acc = 89.75% | Kappa = 0.80

---------- Sub_19 ----------
Acc = 82.00% | Kappa = 0.64

---------- Sub_20 ----------
Acc = 81.25% | Kappa = 0.62

---------- Sub_21 ----------
Acc = 92.50% | Kappa = 0.85

---------- Sub_22 ----------
Acc = 85.50% | Kappa = 0.71

---------- Sub_23 ----------
Acc = 73.50% | Kappa = 0.47

---------- Sub_24 ----------
Acc = 58.00% | Kappa = 0.16

---------- Sub_25 ----------
Acc = 79.00% | Kappa = 0.58

---------- Sub_26 ----------
Acc = 68.00% | Kappa = 0.36

---------- Sub_27 ----------
Acc = 70.75% | Kappa = 0.42

---------- Sub_28 ----------
Acc = 97.00% | Kappa = 0.94

---------- Sub_29 ----------
Acc = 56.25% | Kappa = 0.12

---------- Sub_30 ----------
Acc = 80.75% | Kappa = 0.62

---------- Sub_31 ----------
Acc = 78.50% | Kappa = 0.57

---------- Sub_32 ----------
Acc = 87.75% | Kappa = 0.75

---------- Sub_33 ----------
Acc = 97.00% | Kappa = 0.94

---------- Sub_34 ----------
Acc = 57.50% | Kappa = 0.15

---------- Sub_35 ----------
Acc = 68.75% | Kappa = 0.38

---------- Sub_36 ----------
Acc = 96.50% | Kappa = 0.93

---------- Sub_37 ----------
Acc = 95.50% | Kappa = 0.91

---------- Sub_38 ----------
Acc = 66.50% | Kappa = 0.33

---------- Sub_39 ----------
Acc = 88.25% | Kappa = 0.76

---------- Sub_40 ----------
Acc = 74.50% | Kappa = 0.49

---------- Sub_41 ----------
Acc = 67.75% | Kappa = 0.36

---------- Sub_42 ----------
Acc = 75.75% | Kappa = 0.51

---------- Sub_43 ----------
Acc = 85.25% | Kappa = 0.71

---------- Sub_44 ----------
Acc = 95.25% | Kappa = 0.90

---------- Sub_45 ----------
Acc = 85.75% | Kappa = 0.72

---------- Sub_46 ----------
Acc = 77.25% | Kappa = 0.54

---------- Sub_47 ----------
Acc = 73.50% | Kappa = 0.47

---------- Sub_48 ----------
Acc = 64.25% | Kappa = 0.29

---------- Sub_49 ----------
Acc = 70.50% | Kappa = 0.41

---------- Sub_50 ----------
Acc = 58.75% | Kappa = 0.18

---------- Sub_51 ----------
Acc = 67.50% | Kappa = 0.35

---------- Sub_52 ----------
Acc = 80.25% | Kappa = 0.61

---------- Sub_53 ----------
Acc = 70.75% | Kappa = 0.42

---------- Sub_54 ----------
Acc = 61.25% | Kappa = 0.23

---------- MODEL ----------
Acc = 77.41% | Kappa = 0.55
