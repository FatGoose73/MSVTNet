[Start Time]: Thu Jan 11 15:35:34 2024
[DPEEG Version]: 0.3.5
[Description]: None
[KFold:
  [trainer]: [Network architecture]:
             MSVTNet(
               (mstsconv): ModuleList(
                 (0): Sequential(
                   (0): TSConv(
                     (0): Conv2d(1, 9, kernel_size=(1, 15), stride=(1, 1), padding=same, bias=False)
                     (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (2): Conv2d(9, 18, kernel_size=(22, 1), stride=(1, 1), groups=9, bias=False)
                     (3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (4): ELU(alpha=1.0)
                     (5): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)
                     (6): Dropout(p=0.3, inplace=False)
                     (7): Conv2d(18, 18, kernel_size=(1, 15), stride=(1, 1), padding=same, groups=18, bias=False)
                     (8): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (9): ELU(alpha=1.0)
                     (10): AvgPool2d(kernel_size=(1, 7), stride=(1, 7), padding=0)
                     (11): Dropout(p=0.3, inplace=False)
                   )
                   (1): Rearrange('b d 1 t -> b t d')
                 )
                 (1): Sequential(
                   (0): TSConv(
                     (0): Conv2d(1, 9, kernel_size=(1, 31), stride=(1, 1), padding=same, bias=False)
                     (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (2): Conv2d(9, 18, kernel_size=(22, 1), stride=(1, 1), groups=9, bias=False)
                     (3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (4): ELU(alpha=1.0)
                     (5): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)
                     (6): Dropout(p=0.3, inplace=False)
                     (7): Conv2d(18, 18, kernel_size=(1, 15), stride=(1, 1), padding=same, groups=18, bias=False)
                     (8): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (9): ELU(alpha=1.0)
                     (10): AvgPool2d(kernel_size=(1, 7), stride=(1, 7), padding=0)
                     (11): Dropout(p=0.3, inplace=False)
                   )
                   (1): Rearrange('b d 1 t -> b t d')
                 )
                 (2): Sequential(
                   (0): TSConv(
                     (0): Conv2d(1, 9, kernel_size=(1, 63), stride=(1, 1), padding=same, bias=False)
                     (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (2): Conv2d(9, 18, kernel_size=(22, 1), stride=(1, 1), groups=9, bias=False)
                     (3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (4): ELU(alpha=1.0)
                     (5): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)
                     (6): Dropout(p=0.3, inplace=False)
                     (7): Conv2d(18, 18, kernel_size=(1, 15), stride=(1, 1), padding=same, groups=18, bias=False)
                     (8): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (9): ELU(alpha=1.0)
                     (10): AvgPool2d(kernel_size=(1, 7), stride=(1, 7), padding=0)
                     (11): Dropout(p=0.3, inplace=False)
                   )
                   (1): Rearrange('b d 1 t -> b t d')
                 )
                 (3): Sequential(
                   (0): TSConv(
                     (0): Conv2d(1, 9, kernel_size=(1, 125), stride=(1, 1), padding=same, bias=False)
                     (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (2): Conv2d(9, 18, kernel_size=(22, 1), stride=(1, 1), groups=9, bias=False)
                     (3): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (4): ELU(alpha=1.0)
                     (5): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)
                     (6): Dropout(p=0.3, inplace=False)
                     (7): Conv2d(18, 18, kernel_size=(1, 15), stride=(1, 1), padding=same, groups=18, bias=False)
                     (8): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                     (9): ELU(alpha=1.0)
                     (10): AvgPool2d(kernel_size=(1, 7), stride=(1, 7), padding=0)
                     (11): Dropout(p=0.3, inplace=False)
                   )
                   (1): Rearrange('b d 1 t -> b t d')
                 )
               )
               (branch_head): ModuleList(
                 (0-3): 4 x ClsHead(
                   (0): Flatten(start_dim=1, end_dim=-1)
                   (1): Linear(in_features=306, out_features=4, bias=True)
                   (2): LogSoftmax(dim=1)
                 )
               )
               (transformer): Transformer(
                 (pos_embedding): PositionalEncoding()
                 (dropout): Dropout(p=0.5, inplace=False)
                 (trans): TransformerEncoder(
                   (layers): ModuleList(
                     (0-1): 2 x TransformerEncoderLayer(
                       (self_attn): MultiheadAttention(
                         (out_proj): NonDynamicallyQuantizableLinear(in_features=72, out_features=72, bias=True)
                       )
                       (linear1): Linear(in_features=72, out_features=72, bias=True)
                       (dropout): Dropout(p=0.5, inplace=False)
                       (linear2): Linear(in_features=72, out_features=72, bias=True)
                       (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
                       (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
                       (dropout1): Dropout(p=0.5, inplace=False)
                       (dropout2): Dropout(p=0.5, inplace=False)
                     )
                   )
                   (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
                 )
               )
               (last_head): ClsHead(
                 (0): Flatten(start_dim=1, end_dim=-1)
                 (1): Linear(in_features=72, out_features=4, bias=True)
                 (2): LogSoftmax(dim=1)
               )
             )
             ====================================================================================================
             Layer (type:depth-idx)                             Output Shape              Param #
             ====================================================================================================
             MSVTNet                                            [1, 4]                    --
             ├─ModuleList: 1-1                                  --                        --
             │    └─Sequential: 2-1                             [1, 17, 18]               --
             │    │    └─TSConv: 3-1                            [1, 18, 1, 17]            891
             │    │    └─Rearrange: 3-2                         [1, 17, 18]               --
             │    └─Sequential: 2-2                             [1, 17, 18]               --
             │    │    └─TSConv: 3-3                            [1, 18, 1, 17]            1,035
             │    │    └─Rearrange: 3-4                         [1, 17, 18]               --
             │    └─Sequential: 2-3                             [1, 17, 18]               --
             │    │    └─TSConv: 3-5                            [1, 18, 1, 17]            1,323
             │    │    └─Rearrange: 3-6                         [1, 17, 18]               --
             │    └─Sequential: 2-4                             [1, 17, 18]               --
             │    │    └─TSConv: 3-7                            [1, 18, 1, 17]            1,881
             │    │    └─Rearrange: 3-8                         [1, 17, 18]               --
             ├─ModuleList: 1-2                                  --                        --
             │    └─ClsHead: 2-5                                [1, 4]                    --
             │    │    └─Flatten: 3-9                           [1, 306]                  --
             │    │    └─Linear: 3-10                           [1, 4]                    1,228
             │    │    └─LogSoftmax: 3-11                       [1, 4]                    --
             │    └─ClsHead: 2-6                                [1, 4]                    --
             │    │    └─Flatten: 3-12                          [1, 306]                  --
             │    │    └─Linear: 3-13                           [1, 4]                    1,228
             │    │    └─LogSoftmax: 3-14                       [1, 4]                    --
             │    └─ClsHead: 2-7                                [1, 4]                    --
             │    │    └─Flatten: 3-15                          [1, 306]                  --
             │    │    └─Linear: 3-16                           [1, 4]                    1,228
             │    │    └─LogSoftmax: 3-17                       [1, 4]                    --
             │    └─ClsHead: 2-8                                [1, 4]                    --
             │    │    └─Flatten: 3-18                          [1, 306]                  --
             │    │    └─Linear: 3-19                           [1, 4]                    1,228
             │    │    └─LogSoftmax: 3-20                       [1, 4]                    --
             ├─Transformer: 1-3                                 [1, 72]                   72
             │    └─PositionalEncoding: 2-9                     [1, 18, 72]               1,296
             │    └─Dropout: 2-10                               [1, 18, 72]               --
             │    └─TransformerEncoder: 2-11                    [1, 18, 72]               --
             │    │    └─ModuleList: 3-21                       --                        63,648
             │    │    └─LayerNorm: 3-22                        [1, 18, 72]               144
             ├─ClsHead: 1-4                                     [1, 4]                    --
             │    └─Flatten: 2-12                               [1, 72]                   --
             │    └─Linear: 2-13                                [1, 4]                    292
             │    └─LogSoftmax: 2-14                            [1, 4]                    --
             ====================================================================================================
             Total params: 75,494
             Trainable params: 75,494
             Non-trainable params: 0
             Total mult-adds (M): 48.06
             ====================================================================================================
             Input size (MB): 0.09
             Forward/backward pass size (MB): 13.99
             Params size (MB): 0.05
             Estimated Total Size (MB): 14.12
             ====================================================================================================
             [Loss function]: JointCrossEntoryLoss()
             [Optimizer]: Adam
             [Learning rate]: 0.001
             [Grad Acc]: 1
             [Batch Size]: 64
  [k]: 5
  [out_folder]: out
  [max_epochs_s1]: 1500
  [max_epochs_s2]: 600
  [no_increase_epochs]: 100
  [second_stage]: True
  [load_best_state]: True
  [var_check]: val_inacc
  [isolate_testset]: True
  [shuffle]: True
  [seed]: 42
  [verbose]: INFO
]
[BCICIV2A:
  [subjects]: None
  [tmin]: 0
  [tmax]: 4
  [preprocess]: None
  [transforms]: ComposeTransforms(
                 (0): Normalization(mode=z-score, factor_new=0.001, verbose=None)
                 (1): Augmentation(method=segmentation_and_reconstruction, only_train=True, kwargs={'multiply': 1})
                 (2): Unsqueeze(dim=1)
                )
  [test_size]: 0.25
  [mode]: single_ses
  [picks]: None
  [baseline]: None
  [seed]: 42
  [verbose]: None
]
---------- Sub_1 ----------
Acc = 81.67% | Kappa = 0.76

---------- Sub_2 ----------
Acc = 64.17% | Kappa = 0.52

---------- Sub_3 ----------
Acc = 93.61% | Kappa = 0.91

---------- Sub_4 ----------
Acc = 77.78% | Kappa = 0.70

---------- Sub_5 ----------
Acc = 80.56% | Kappa = 0.74

---------- Sub_6 ----------
Acc = 78.61% | Kappa = 0.71

---------- Sub_7 ----------
Acc = 90.56% | Kappa = 0.87

---------- Sub_8 ----------
Acc = 87.50% | Kappa = 0.83

---------- Sub_9 ----------
Acc = 88.61% | Kappa = 0.85

---------- MODEL ----------
Acc = 82.56% | Kappa = 0.77
