[Start Time]: Fri May 10 14:50:34 2024
[DPEEG Version]: 0.3.6
[Description]: None
[LOSO_HO:
  [trainer]: [Network architecture]:
             IFNet(
               (sConv): Sequential(
                 (0): Conv1d(6, 128, kernel_size=(1,), stride=(1,), groups=2, bias=False)
                 (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
               )
               (tConv): ModuleList(
                 (0): Sequential(
                   (0): Conv1d(64, 64, kernel_size=(63,), stride=(1,), padding=(31,), groups=64, bias=False)
                   (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                 )
                 (1): Sequential(
                   (0): Conv1d(64, 64, kernel_size=(31,), stride=(1,), padding=(15,), groups=64, bias=False)
                   (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                 )
               )
               (interFre): InterFre()
               (downSamp): Sequential(
                 (0): AvgPool1d(kernel_size=(125,), stride=(125,), padding=(0,))
                 (1): Dropout(p=0.5, inplace=False)
               )
               (fc): Sequential(
                 (0): Flatten(start_dim=1, end_dim=-1)
                 (1): Linear(in_features=512, out_features=2, bias=True)
                 (2): LogSoftmax(dim=1)
               )
             )
             ==========================================================================================
             Layer (type:depth-idx)                   Output Shape              Param #
             ==========================================================================================
             IFNet                                    [1, 2]                    --
             ├─Sequential: 1-1                        [1, 128, 1000]            --
             │    └─Conv1d: 2-1                       [1, 128, 1000]            384
             │    └─BatchNorm1d: 2-2                  [1, 128, 1000]            256
             ├─ModuleList: 1-2                        --                        --
             │    └─Sequential: 2-3                   [1, 64, 1000]             --
             │    │    └─Conv1d: 3-1                  [1, 64, 1000]             4,032
             │    │    └─BatchNorm1d: 3-2             [1, 64, 1000]             128
             │    └─Sequential: 2-4                   [1, 64, 1000]             --
             │    │    └─Conv1d: 3-3                  [1, 64, 1000]             1,984
             │    │    └─BatchNorm1d: 3-4             [1, 64, 1000]             128
             ├─InterFre: 1-3                          [1, 64, 1000]             --
             ├─Sequential: 1-4                        [1, 64, 8]                --
             │    └─AvgPool1d: 2-5                    [1, 64, 8]                --
             │    └─Dropout: 2-6                      [1, 64, 8]                --
             ├─Sequential: 1-5                        [1, 2]                    --
             │    └─Flatten: 2-7                      [1, 512]                  --
             │    └─Linear: 2-8                       [1, 2]                    1,026
             │    └─LogSoftmax: 2-9                   [1, 2]                    --
             ==========================================================================================
             Total params: 7,938
             Trainable params: 7,938
             Non-trainable params: 0
             Total mult-adds (M): 6.40
             ==========================================================================================
             Input size (MB): 0.02
             Forward/backward pass size (MB): 4.10
             Params size (MB): 0.03
             Estimated Total Size (MB): 4.15
             ==========================================================================================
             [Loss function]: NLLLoss
             [Optimizer]: <class 'dpeeg.models.IFNet.IFNetAdamW'>
             [Learning rate]: 0.002
             [Grad Acc]: 1
             [Batch Size]: 512
  [out_folder]: out
  [max_epochs_s1]: 500
  [no_increase_epochs]: 40
  [var_check]: None
  [split_val]: True
  [test_size]: 0.25
  [second_stage]: True
  [load_best_state]: True
  [max_epochs_s2]: 200
  [seed]: 42
  [verbose]: INFO
]
[BCICIV2B:
  [subjects]: None
  [tmin]: 0
  [tmax]: 4
  [preprocess]: None
  [transforms]: ComposeTransforms(
                 (0): Normalization(mode=z-score, factor_new=0.001, verbose=None)
                 (1): ApplyFunc(func=<function cfc_filter at 0x7fcbcfda44c0>, mode=all, data=True, kwargs={'filter_bank': [[4, 16], [16, 40]]})
                )
  [test_size]: 0.25
  [mode]: cross_ses
  [test_sessions]: [3, 4]
  [picks]: None
  [baseline]: None
  [seed]: 42
  [verbose]: None
]
---------- Sub_1 ----------
Acc = 72.78% | Kappa = 0.46

---------- Sub_2 ----------
Acc = 60.29% | Kappa = 0.21

---------- Sub_3 ----------
Acc = 56.11% | Kappa = 0.12

---------- Sub_4 ----------
Acc = 80.81% | Kappa = 0.62

---------- Sub_5 ----------
Acc = 75.14% | Kappa = 0.50

---------- Sub_6 ----------
Acc = 80.83% | Kappa = 0.62

---------- Sub_7 ----------
Acc = 73.47% | Kappa = 0.47

---------- Sub_8 ----------
Acc = 72.50% | Kappa = 0.45

---------- Sub_9 ----------
Acc = 80.00% | Kappa = 0.60

-------------- MODEL
Acc = 72.44%±8.30 | Kappa = 0.45
