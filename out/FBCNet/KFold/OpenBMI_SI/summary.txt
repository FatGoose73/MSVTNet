[Start Time]: Sat Jan  6 18:34:51 2024
[DPEEG Version]: 0.3.5
[Description]: None
[KFold:
  [trainer]: [Network architecture]:
             FBCNet(
               (scb): Sequential(
                 (0): Conv2dWithNorm(9, 288, kernel_size=(20, 1), stride=(1, 1), groups=9, max_norm=2, p=2)
                 (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                 (2): swish()
               )
               (temporal_layer): LogVarLayer()
               (head): Sequential(
                 (0): Flatten(start_dim=1, end_dim=-1)
                 (1): LinearWithNorm(in_features=1152, out_features=2, bias=True, max_norm=0.5, p=2)
                 (2): LogSoftmax(dim=1)
               )
             )
             =================================================================
             Layer (type:depth-idx)                   Param #
             =================================================================
             FBCNet                                   --
             ├─Sequential: 1-1                        --
             │    └─Conv2dWithNorm: 2-1               6,048
             │    └─BatchNorm2d: 2-2                  576
             │    └─swish: 2-3                        --
             ├─LogVarLayer: 1-2                       --
             ├─Sequential: 1-3                        --
             │    └─Flatten: 2-4                      --
             │    └─LinearWithNorm: 2-5               2,306
             │    └─LogSoftmax: 2-6                   --
             =================================================================
             Total params: 8,930
             Trainable params: 8,930
             Non-trainable params: 0
             =================================================================
             [Loss function]: NLLLoss
             [Optimizer]: Adam
             [Learning rate]: 0.001
             [Grad Acc]: 1
             [Batch Size]: 128
  [k]: 5
  [out_folder]: out
  [max_epochs_s1]: 1500
  [max_epochs_s2]: 600
  [no_increase_epochs]: 100
  [second_stage]: True
  [load_best_state]: True
  [var_check]: val_inacc
  [isolate_testset]: True
  [shuffle]: True
  [seed]: 42
  [verbose]: INFO
]
[Custom dataset]
---------- Sub_1 ----------
Acc = 87.70% | Kappa = 0.75

---------- Sub_2 ----------
Acc = 64.90% | Kappa = 0.30

---------- Sub_3 ----------
Acc = 96.20% | Kappa = 0.92

---------- Sub_4 ----------
Acc = 76.70% | Kappa = 0.53

---------- Sub_5 ----------
Acc = 87.60% | Kappa = 0.75

---------- Sub_6 ----------
Acc = 82.20% | Kappa = 0.64

---------- Sub_7 ----------
Acc = 65.90% | Kappa = 0.32

---------- Sub_8 ----------
Acc = 65.20% | Kappa = 0.30

---------- Sub_9 ----------
Acc = 79.90% | Kappa = 0.60

---------- Sub_10 ----------
Acc = 62.70% | Kappa = 0.25

---------- Sub_11 ----------
Acc = 52.10% | Kappa = 0.04

---------- Sub_12 ----------
Acc = 69.90% | Kappa = 0.40

---------- Sub_13 ----------
Acc = 54.70% | Kappa = 0.09

---------- Sub_14 ----------
Acc = 59.00% | Kappa = 0.18

---------- Sub_15 ----------
Acc = 59.60% | Kappa = 0.19

---------- Sub_16 ----------
Acc = 57.40% | Kappa = 0.15

---------- Sub_17 ----------
Acc = 58.00% | Kappa = 0.16

---------- Sub_18 ----------
Acc = 87.00% | Kappa = 0.74

---------- Sub_19 ----------
Acc = 69.30% | Kappa = 0.39

---------- Sub_20 ----------
Acc = 71.90% | Kappa = 0.44

---------- Sub_21 ----------
Acc = 99.20% | Kappa = 0.98

---------- Sub_22 ----------
Acc = 67.70% | Kappa = 0.35

---------- Sub_23 ----------
Acc = 66.10% | Kappa = 0.32

---------- Sub_24 ----------
Acc = 52.00% | Kappa = 0.04

---------- Sub_25 ----------
Acc = 66.70% | Kappa = 0.33

---------- Sub_26 ----------
Acc = 54.50% | Kappa = 0.09

---------- Sub_27 ----------
Acc = 55.90% | Kappa = 0.12

---------- Sub_28 ----------
Acc = 95.70% | Kappa = 0.91

---------- Sub_29 ----------
Acc = 93.50% | Kappa = 0.87

---------- Sub_30 ----------
Acc = 68.80% | Kappa = 0.38

---------- Sub_31 ----------
Acc = 67.20% | Kappa = 0.34

---------- Sub_32 ----------
Acc = 90.10% | Kappa = 0.80

---------- Sub_33 ----------
Acc = 97.20% | Kappa = 0.94

---------- Sub_34 ----------
Acc = 55.30% | Kappa = 0.11

---------- Sub_35 ----------
Acc = 73.60% | Kappa = 0.47

---------- Sub_36 ----------
Acc = 97.00% | Kappa = 0.94

---------- Sub_37 ----------
Acc = 95.20% | Kappa = 0.90

---------- Sub_38 ----------
Acc = 57.40% | Kappa = 0.15

---------- Sub_39 ----------
Acc = 83.00% | Kappa = 0.66

---------- Sub_40 ----------
Acc = 58.00% | Kappa = 0.16

---------- Sub_41 ----------
Acc = 57.90% | Kappa = 0.16

---------- Sub_42 ----------
Acc = 65.30% | Kappa = 0.31

---------- Sub_43 ----------
Acc = 76.40% | Kappa = 0.53

---------- Sub_44 ----------
Acc = 97.90% | Kappa = 0.96

---------- Sub_45 ----------
Acc = 91.80% | Kappa = 0.84

---------- Sub_46 ----------
Acc = 74.60% | Kappa = 0.49

---------- Sub_47 ----------
Acc = 60.50% | Kappa = 0.21

---------- Sub_48 ----------
Acc = 62.40% | Kappa = 0.25

---------- Sub_49 ----------
Acc = 63.60% | Kappa = 0.27

---------- Sub_50 ----------
Acc = 55.60% | Kappa = 0.11

---------- Sub_51 ----------
Acc = 58.80% | Kappa = 0.18

---------- Sub_52 ----------
Acc = 76.70% | Kappa = 0.53

---------- Sub_53 ----------
Acc = 54.90% | Kappa = 0.10

---------- Sub_54 ----------
Acc = 58.60% | Kappa = 0.17

---------- MODEL ----------
Acc = 71.43% | Kappa = 0.43
