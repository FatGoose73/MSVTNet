[Start Time]: Mon Jan  8 12:42:41 2024
[DPEEG Version]: 0.3.5
[Description]: None
[LOSO_HO:
  [trainer]: [Network architecture]:
             FBCNet(
               (scb): Sequential(
                 (0): Conv2dWithNorm(9, 288, kernel_size=(3, 1), stride=(1, 1), groups=9, max_norm=2, p=2)
                 (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                 (2): swish()
               )
               (temporal_layer): LogVarLayer()
               (head): Sequential(
                 (0): Flatten(start_dim=1, end_dim=-1)
                 (1): LinearWithNorm(in_features=1152, out_features=2, bias=True, max_norm=0.5, p=2)
                 (2): LogSoftmax(dim=1)
               )
             )
             ==========================================================================================
             Layer (type:depth-idx)                   Output Shape              Param #
             ==========================================================================================
             FBCNet                                   [1, 2]                    --
             ├─Sequential: 1-1                        [1, 288, 1, 1000]         --
             │    └─Conv2dWithNorm: 2-1               [1, 288, 1, 1000]         1,152
             │    └─BatchNorm2d: 2-2                  [1, 288, 1, 1000]         576
             │    └─swish: 2-3                        [1, 288, 1, 1000]         --
             ├─LogVarLayer: 1-2                       [1, 288, 4, 1]            --
             ├─Sequential: 1-3                        [1, 2]                    --
             │    └─Flatten: 2-4                      [1, 1152]                 --
             │    └─LinearWithNorm: 2-5               [1, 2]                    2,306
             │    └─LogSoftmax: 2-6                   [1, 2]                    --
             ==========================================================================================
             Total params: 4,034
             Trainable params: 4,034
             Non-trainable params: 0
             Total mult-adds (M): 1.15
             ==========================================================================================
             Input size (MB): 0.11
             Forward/backward pass size (MB): 4.61
             Params size (MB): 0.02
             Estimated Total Size (MB): 4.73
             ==========================================================================================
             [Loss function]: NLLLoss
             [Optimizer]: Adam
             [Learning rate]: 0.002
             [Grad Acc]: 1
             [Batch Size]: 512
  [out_folder]: out
  [max_epochs_s1]: 500
  [no_increase_epochs]: 40
  [var_check]: None
  [split_val]: True
  [test_size]: 0.25
  [second_stage]: True
  [load_best_state]: True
  [max_epochs_s2]: 200
  [seed]: 42
  [verbose]: INFO
]
[BCICIV2B:
  [subjects]: None
  [tmin]: 0
  [tmax]: 4
  [preprocess]: None
  [transforms]: ComposeTransforms(
                 (0): Normalization(mode=z-score, factor_new=0.001, verbose=None)
                 (1): FilterBank(freq=250, filter_bank=[[4, 8], [8, 12], [12, 16], [16, 20], [20, 24], [24, 28], [28, 32], [32, 36], [36, 40]], transition_bandwidth=2.0, gstop=30, gpass=3)
                )
  [test_size]: 0.25
  [mode]: cross_ses
  [test_sessions]: [3, 4]
  [picks]: None
  [baseline]: None
  [seed]: 42
  [verbose]: None
]
---------- Sub_1 ----------
Acc = 74.03% | Kappa = 0.48

---------- Sub_2 ----------
Acc = 59.12% | Kappa = 0.18

---------- Sub_3 ----------
Acc = 61.67% | Kappa = 0.23

---------- Sub_4 ----------
Acc = 80.54% | Kappa = 0.61

---------- Sub_5 ----------
Acc = 78.78% | Kappa = 0.58

---------- Sub_6 ----------
Acc = 73.33% | Kappa = 0.47

---------- Sub_7 ----------
Acc = 70.97% | Kappa = 0.42

---------- Sub_8 ----------
Acc = 74.34% | Kappa = 0.49

---------- Sub_9 ----------
Acc = 76.94% | Kappa = 0.54

---------- MODEL ----------
Acc = 72.19% | Kappa = 0.44
